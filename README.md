Eye-Controlled Mouse Using Python, OpenCV, MediaPipe, and PyAutoGUI
Status: Work in Progress ðŸš§

Overview
The Eye-Controlled Mouse is an innovative project aimed at enhancing accessibility by enabling hands-free computer navigation using eye movements. By leveraging Python and computer vision libraries such as OpenCV, MediaPipe, and PyAutoGUI, this project tracks eye movement and translates it into cursor control.

This project is in development, and future updates will include additional features and performance improvements.

Features (Planned and Implemented)
Real-time Eye Tracking: Detect and track eye movement using MediaPipe. âœ…
Cursor Control: Move the mouse cursor based on gaze direction. âœ…
Blink Detection (In Progress): Detect blinks to simulate click actions.
Calibration (Upcoming): Customize sensitivity and tracking for different users.
Multi-Platform Support (Upcoming): Ensure compatibility across Windows, Linux, and macOS.
Technology Stack
Programming Language: Python
Libraries Used:
OpenCV for image processing.
MediaPipe for eye tracking.
PyAutoGUI for mouse control automation.
Setup Instructions
Clone the Repository

bash
Copy code
git clone https://github.com/your-username/eye-controlled-mouse.git
cd eye-controlled-mouse
Install Dependencies
Ensure Python is installed, then run:

bash
Copy code
pip install -r requirements.txt
Run the Project
Execute the script to start tracking:

bash
Copy code
python main.py
Usage:

Position yourself in front of the camera.
Adjust lighting for optimal eye tracking.
Project Roadmap
 Set up basic eye-tracking using MediaPipe.
 Integrate cursor control with PyAutoGUI.
 Add blink detection for click actions.
 Implement a calibration interface for better accuracy.
 Create a GUI for user-friendly interaction.
Contributing
This project is open to contributions! Feel free to:

Fork the repository.
Create feature branches.
Submit pull requests with improvements or new features.
Future Goals
Enhance tracking accuracy for varying lighting conditions.
Add support for additional accessibility gestures.
Publish as an open-source tool for public use.
Contact
Feel free to connect with me on LinkedIn or email me at your-email@example.com for collaboration opportunities or feedback.
